{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from vae_auto_encoder import VAEAutoEncoder\n",
    "from image_label_dataset import ImageLabelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_size = 128\n",
    "z_dim_size = 200\n",
    "\n",
    "data_path = './data/celeba/'\n",
    "csv_data_path = './data/celeba/list_attr_celeba.csv'\n",
    "model_save_path = './vae_faces_model.pth'\n",
    "save_folder = './images/celeba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = pd.read_csv(csv_data_path)\n",
    "att.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),])\n",
    "    #transforms.Normalize((0.5, 0.5, 0.5),\n",
    "    #                     (0.5, 0.5, 0.5))])\n",
    "\n",
    "dataset = ImageLabelDataset(data_path,\n",
    "                            csv_data_path,\n",
    "                            transform=transform)\n",
    "\n",
    "dataloader = DataLoader(dataset=dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        num_workers=4,\n",
    "                        pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAEAutoEncoder(4,\n",
    "                       encoder_channels=[3, 32, 64, 64, 64],\n",
    "                       encoder_kernel_sizes=[3, 3, 3, 3],\n",
    "                       encoder_strides=[2, 2, 2, 2],\n",
    "                       decoder_channels=[64, 64, 64, 32, 3],\n",
    "                       decoder_kernel_sizes=[3, 3, 3, 3],\n",
    "                       decoder_strides=[2, 2, 2, 2],\n",
    "                       linear_sizes=[4096, z_dim_size],\n",
    "                       view_size=[-1, 64, 8, 8],\n",
    "                       use_batch_norm=True,\n",
    "                       use_dropout=True).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_show = 10\n",
    "\n",
    "inputs, _ = next(iter(dataloader))\n",
    "\n",
    "inputs = inputs.to(device)\n",
    "reconst_images, mu, log_var = model(inputs)\n",
    "print(reconst_images.shape)\n",
    "print(nn.MSELoss()(reconst_images, inputs))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(inputs[:10],\n",
    "                                         nrow=10,\n",
    "                                         padding=2,\n",
    "                                         normalize=True).cpu(), (1, 2, 0)))\n",
    "plt.savefig(os.path.join(save_folder, 'input_images.png'))\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(reconst_images[:10],\n",
    "                                         nrow=10,\n",
    "                                         padding=2,\n",
    "                                         normalize=True).detach().cpu(), (1, 2, 0)))\n",
    "plt.savefig(os.path.join(save_folder, 'output_images.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_list = []\n",
    "\n",
    "for i, (inputs, _) in enumerate(dataloader):\n",
    "    inputs = inputs.to(device)\n",
    "    outputs, mu, log_var = model.encode(inputs)\n",
    "        \n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    output_list.append(outputs)\n",
    "    \n",
    "    if i == 20:\n",
    "        break\n",
    "\n",
    "output_np = np.vstack(output_list)\n",
    "\n",
    "x = np.linspace(-3, 3, 100)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "fig.subplots_adjust(hspace=0.6, wspace=0.4)\n",
    "\n",
    "for i in range(50):\n",
    "    ax = fig.add_subplot(5, 10, i + 1)\n",
    "    ax.hist(output_np[:, i], density=True, bins=20)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.35, str(i), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "    ax.plot(x, norm.pdf(x))\n",
    "\n",
    "fig.savefig(os.path.join(save_folder, 'distribution.png'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_show = 30\n",
    "\n",
    "z_new = torch.randn(size=(num_to_show, z_dim_size), device=device)\n",
    "\n",
    "reconst = model.decode(z_new)\n",
    "    \n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(reconst_images[:30],\n",
    "                                         nrow=10,\n",
    "                                         padding=2,\n",
    "                                         normalize=True).detach().cpu(), (1, 2, 0)))\n",
    "plt.savefig(os.path.join(save_folder, 'generated_images.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_from_label(label, batch_size):\n",
    "    image_label_dataset = ImageLabelDataset(data_path,\n",
    "                                            csv_data_path,\n",
    "                                            transform=transform,\n",
    "                                            label=label)\n",
    "\n",
    "    image_label_dataloader = DataLoader(image_label_dataset,\n",
    "                                        batch_size=batch_size,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=4,\n",
    "                                        pin_memory=True)\n",
    "\n",
    "    origin = np.zeros(shape=z_dim_size, dtype='float32')\n",
    "    current_sum_POS = np.zeros(shape=z_dim_size, dtype='float32')\n",
    "    current_n_POS = 0\n",
    "    current_mean_POS = np.zeros(shape=z_dim_size, dtype='float32')\n",
    "\n",
    "    current_sum_NEG = np.zeros(shape=z_dim_size, dtype='float32')\n",
    "    current_n_NEG = 0\n",
    "    current_mean_NEG = np.zeros(shape=z_dim_size, dtype='float32')\n",
    "\n",
    "    current_vector = np.zeros(shape=z_dim_size, dtype='float32')\n",
    "    current_dist = 0\n",
    "\n",
    "    print('label: ' + label)\n",
    "    print('images : POS move : NEG move :distance : ùõ• distance')\n",
    "    while(current_n_POS < 10000):\n",
    "        for _, (inputs, attribute) in enumerate(image_label_dataloader, 0):\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            outputs, mu, log_var = model.encode(inputs)\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "\n",
    "            z_POS = outputs[attribute == 1]\n",
    "            z_NEG = outputs[attribute == -1]\n",
    "\n",
    "            if len(z_POS) > 0:\n",
    "                current_sum_POS = current_sum_POS + np.sum(z_POS, axis=0)\n",
    "                current_n_POS += len(z_POS)\n",
    "                new_mean_POS = current_sum_POS / current_n_POS\n",
    "                movement_POS = np.linalg.norm(new_mean_POS - current_mean_POS)\n",
    "\n",
    "            if len(z_NEG) > 0:\n",
    "                current_sum_NEG = current_sum_NEG + np.sum(z_NEG, axis=0)\n",
    "                current_n_NEG += len(z_NEG)\n",
    "                new_mean_NEG = current_sum_NEG / current_n_NEG\n",
    "                movement_NEG = np.linalg.norm(new_mean_NEG - current_mean_NEG)\n",
    "\n",
    "            current_vector = new_mean_POS - new_mean_NEG\n",
    "            new_dist = np.linalg.norm(current_vector)\n",
    "            dist_change = new_dist - current_dist\n",
    "\n",
    "            print(str(current_n_POS)\n",
    "                  + '\\t: ' + str(np.round(movement_POS, 3))\n",
    "                  + '\\t: ' + str(np.round(movement_NEG, 3))\n",
    "                  + '\\t: ' + str(np.round(new_dist, 3))\n",
    "                  + '\\t: ' + str(np.round(dist_change, 3))\n",
    "                  )\n",
    "\n",
    "            current_mean_POS = np.copy(new_mean_POS)\n",
    "            current_mean_NEG = np.copy(new_mean_NEG)\n",
    "            current_dist = np.copy(new_dist)\n",
    "\n",
    "            if np.sum([movement_POS, movement_NEG]) < 0.08:\n",
    "                current_vector = current_vector / current_dist\n",
    "                print('Found the ' + label + ' vector')\n",
    "                break\n",
    "\n",
    "        return current_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vector_to_images(label, feature_vec):\n",
    "    num_to_show = 5\n",
    "    factors = [-4, -3, -2, -1, 0, 1, 2, 3, 4]\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    batch = next(iter(dataloader))\n",
    "    inputs, attributes = batch\n",
    "    device_inputs = inputs.to(device)\n",
    "        \n",
    "    z_points, mu, log_var = model.encode(device_inputs)\n",
    "    z_points = z_points.detach().cpu()\n",
    "    \n",
    "    for i in range(num_to_show):\n",
    "        images.append(inputs[i])\n",
    "        for factor in factors:\n",
    "            changed_z_point = z_points[i] + feature_vec * factor\n",
    "            changed_images = model.decode(changed_z_point.to(device))\n",
    "            changed_images = changed_images.detach().cpu()\n",
    "            \n",
    "            images.append(changed_images.squeeze(0))\n",
    "        \n",
    "    plt.figure(figsize=(18, 10))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(vutils.make_grid(images,\n",
    "                                             nrow=10,\n",
    "                                             padding=2,\n",
    "                                             normalize=True), (1, 2, 0)))\n",
    "    plt.savefig(os.path.join(save_folder, label + '.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 500\n",
    "attractive_vec = get_vector_from_label('Attractive', BATCH_SIZE)\n",
    "mouth_open_vec = get_vector_from_label('Mouth_Slightly_Open', BATCH_SIZE)\n",
    "smiling_vec = get_vector_from_label('Smiling', BATCH_SIZE)\n",
    "lipstick_vec = get_vector_from_label('Wearing_Lipstick', BATCH_SIZE)\n",
    "young_vec = get_vector_from_label('High_Cheekbones', BATCH_SIZE)\n",
    "male_vec = get_vector_from_label('Male', BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyeglasses_vec = get_vector_from_label('Eyeglasses', BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blonde_vec = get_vector_from_label('Blond_Hair', BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Attractive Vector')\n",
    "add_vector_to_images('Attractive', attractive_vec)\n",
    "\n",
    "print('Mouth Open Vector')\n",
    "add_vector_to_images('Mouth_Open', mouth_open_vec)\n",
    "\n",
    "print('Smiling Vector')\n",
    "add_vector_to_images('Smiling', smiling_vec)\n",
    "\n",
    "print('Lipstick Vector')\n",
    "add_vector_to_images('Lipstick', lipstick_vec)\n",
    "\n",
    "print('Young Vector')\n",
    "add_vector_to_images('Young', young_vec)\n",
    "\n",
    "print('Male Vector')\n",
    "add_vector_to_images('Male', male_vec)\n",
    "\n",
    "print('Eyeglasses Vector')\n",
    "add_vector_to_images('Eyeglasses', eyeglasses_vec)\n",
    "\n",
    "print('Blond Vector')\n",
    "add_vector_to_images('Blond', blonde_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morph_faces(start_image_filename, end_image_filename):\n",
    "    factors = np.arange(0, 1, 0.1)\n",
    "    images = []\n",
    "    \n",
    "    start_image = PIL.Image.open(os.path.join(data_path, 'img_align_celeba_png', start_image_filename))\n",
    "    end_image = PIL.Image.open(os.path.join(data_path, 'img_align_celeba_png', end_image_filename))\n",
    "    \n",
    "    start_image = transform(start_image)\n",
    "    end_image = transform(end_image)\n",
    "    \n",
    "    inputs = torch.stack((start_image, end_image), 0).to(device)\n",
    "    \n",
    "    z_points, mu, log_var = model.encode(inputs)\n",
    "    z_points = z_points.detach().cpu()\n",
    "    \n",
    "    images.append(start_image)\n",
    "    for factor in factors:\n",
    "        changed_z_point = z_points[0] * (1-factor) + z_points[1] * factor\n",
    "        changed_image = model.decode(changed_z_point.to(device))[0]\n",
    "        images.append(changed_image.detach().cpu())\n",
    "        \n",
    "    images.append(end_image)\n",
    "        \n",
    "    plt.figure(figsize=(18, 8))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(vutils.make_grid(images,\n",
    "                                             nrow=12,\n",
    "                                             padding=2,\n",
    "                                             normalize=True), (1, 2, 0)))\n",
    "    plt.savefig(os.path.join(save_folder, start_image_filename[:-4] + '_' + end_image_filename))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_image_file = '000238.png'\n",
    "end_image_file = '000193.png'\n",
    "\n",
    "morph_faces(start_image_file, end_image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_image_file = '000112.png'\n",
    "end_image_file = '000258.png'\n",
    "\n",
    "morph_faces(start_image_file, end_image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_image_file = '000230.png'\n",
    "end_image_file = '000712.png'\n",
    "\n",
    "\n",
    "morph_faces(start_image_file, end_image_file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86945038929e12337cb19f89597171695d197df89cc82498a4710d2d3ad0cdf4"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('gan_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
