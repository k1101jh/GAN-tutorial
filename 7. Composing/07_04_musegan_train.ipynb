{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MuseGAN 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import types\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "from MuseGAN import Generator, Critic\n",
    "from utils import load_music\n",
    "\n",
    "from music21 import midi\n",
    "from music21 import note, stream, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '../data/chorales'\n",
    "file_name = 'Jsb16thSeparated.npz'\n",
    "output_folder = './output/muse_gan'\n",
    "image_save_folder = './images/muse_gan'\n",
    "model_save_path = './muse_gan.pth'\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(image_save_folder, exist_ok=True)\n",
    "\n",
    "mode = 'build'\n",
    "# mode = 'load'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_bars = 2              # 마디 개수\n",
    "n_steps_per_bar = 16    # 한 마디의 16분음표 개수\n",
    "n_pitches = 84          # 음의 범위\n",
    "n_tracks = 4            # 성부의 개수\n",
    "z_dim = 32\n",
    "\n",
    "data_binary, data_ints, raw_data = load_music(data_folder, file_name, n_bars, n_steps_per_bar)\n",
    "data_binary = np.squeeze(data_binary)\n",
    "print(data_binary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_binary):\n",
    "        self.data_binary = torch.FloatTensor(data_binary)\n",
    "        self.data_len = len(self.data_binary)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_binary[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(data_binary)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "dataset_size = len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(z_dim, n_tracks, n_bars, n_steps_per_bar, n_pitches).to(device)\n",
    "critic = Critic(in_channels=n_tracks, n_bars=n_bars).to(device)\n",
    "\n",
    "if mode == 'load':\n",
    "    loaded_model = torch.load(model_save_path)\n",
    "    generator.load_state_dict(loaded_model['Generator'])\n",
    "    critic.load_state_dict(loaded_model['Critic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "n_critic = 5\n",
    "gradient_weight = 10\n",
    "g_learning_rate = 1e-3\n",
    "c_learning_rate = 1e-3\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=g_learning_rate)\n",
    "c_optimizer = optim.Adam(critic.parameters(), lr=c_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty_loss(discriminator, real_images, fake_images):\n",
    "    alpha = torch.rand((real_images.size(0), 1, 1, 1, 1), device=device).requires_grad_(True)\n",
    "    # alpha = alpha.expand_as(real_images)\n",
    "    interpolates = (alpha * real_images.data + ((1 - alpha) * fake_images.data)).requires_grad_(True)\n",
    "    \n",
    "    model_interpolates = discriminator(interpolates)\n",
    "    grad_outputs = torch.ones(model_interpolates.size(), device=device, requires_grad=False)\n",
    "    \n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=model_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=grad_outputs,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "    \n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = torch.mean((gradients.norm(2, dim=1) - 1) ** 2)\n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_pred, y_target):\n",
    "    return -torch.mean(y_pred * y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_losses = []\n",
    "c_losses = []\n",
    "c_losses_real = []\n",
    "c_losses_fake = []\n",
    "grad_penalty_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_c_loss = 0.0\n",
    "    epoch_c_loss_real = 0.0\n",
    "    epoch_c_loss_fake = 0.0\n",
    "    epoch_grad_penalty_loss = 0.0\n",
    "    epoch_g_loss = 0.0\n",
    "    \n",
    "    num_inputs = 0\n",
    "    num_G_inputs = 0\n",
    "    \n",
    "    for i, inputs in enumerate(dataloader):\n",
    "        # 진짜 데이터로 학습\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        for _ in range(n_critic):\n",
    "            critic.zero_grad()\n",
    "            \n",
    "            output = critic(inputs)\n",
    "            # c_loss_real = -output.mean().view(-1)\n",
    "            c_loss_real = wasserstein_loss(output, torch.ones_like(output))\n",
    "            \n",
    "            # 가짜 데이터로 학습\n",
    "            chords_noise = torch.randn(inputs.size(0), z_dim, device=device)\n",
    "            style_noise = torch.randn(inputs.size(0), z_dim, device=device)\n",
    "            melody_noise = torch.randn(inputs.size(0), n_tracks, z_dim, device=device)\n",
    "            groove_noise = torch.randn(inputs.size(0), n_tracks, z_dim, device=device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                fake = generator(chords_noise, style_noise, melody_noise, groove_noise)\n",
    "            output = critic(fake)\n",
    "            # c_loss_fake = output.mean().view(-1)\n",
    "            c_loss_fake = wasserstein_loss(output, -torch.ones_like(output))\n",
    "            \n",
    "            # Gradient Penalty\n",
    "            gradient_penalty = gradient_penalty_loss(critic, inputs, fake) * gradient_weight\n",
    "            \n",
    "            c_loss = c_loss_real + c_loss_fake + gradient_penalty\n",
    "            c_loss.backward(retain_graph=True)\n",
    "            c_optimizer.step()\n",
    "            \n",
    "            epoch_c_loss += c_loss.item() * inputs.size(0)\n",
    "            epoch_c_loss_real += c_loss_real.item() * inputs.size(0)\n",
    "            epoch_c_loss_fake += c_loss_fake.item() * inputs.size(0)\n",
    "            epoch_grad_penalty_loss += gradient_penalty.item() * inputs.size(0)\n",
    "        \n",
    "            num_inputs += inputs.size(0)\n",
    "        \n",
    "        # if (i + 1) % n_critic == 0 or ((i + 1) == len(dataloader) and len(dataloader) < n_critic):\n",
    "        for p in critic.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        # Generator\n",
    "        generator.zero_grad()\n",
    "        chords_noise = torch.randn(batch_size, z_dim, device=device)\n",
    "        style_noise = torch.randn(batch_size, z_dim, device=device)\n",
    "        melody_noise = torch.randn(batch_size, n_tracks, z_dim, device=device)\n",
    "        groove_noise = torch.randn(batch_size, n_tracks, z_dim, device=device)\n",
    "        g_output = generator(chords_noise, style_noise, melody_noise, groove_noise)\n",
    "        output = critic(g_output)\n",
    "        # g_loss = -output.mean().view(-1)\n",
    "        g_loss = wasserstein_loss(output, torch.ones_like(output))\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "            \n",
    "        epoch_g_loss += g_loss.item() * batch_size\n",
    "        \n",
    "        num_G_inputs += batch_size\n",
    "        \n",
    "        for p in critic.parameters():\n",
    "            p.requires_grad = True\n",
    "                \n",
    "    epoch_c_loss /= num_inputs\n",
    "    epoch_c_loss_real /= num_inputs\n",
    "    epoch_c_loss_fake /= num_inputs\n",
    "    epoch_grad_penalty_loss /= num_inputs\n",
    "    epoch_g_loss /= num_G_inputs\n",
    "    \n",
    "    c_losses.append(epoch_c_loss)\n",
    "    c_losses_real.append(epoch_c_loss_real)\n",
    "    c_losses_fake.append(epoch_c_loss_fake)\n",
    "    grad_penalty_losses.append(epoch_grad_penalty_loss)\n",
    "    g_losses.append(epoch_g_loss)\n",
    "    \n",
    "    print('%d [C loss: (%.4f)(R %.4f, F %.4f, G %.4f)] [G loss: %.4f]' %\n",
    "            (epoch + 1, epoch_c_loss, epoch_c_loss_real, epoch_c_loss_fake, epoch_grad_penalty_loss, epoch_g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "models = {\n",
    "    'Generator': generator.state_dict(),\n",
    "    'Critic': critic.state_dict()\n",
    "}\n",
    "torch.save(models, model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.plot([x for x in c_losses], color='black', linewidth=1)\n",
    "plt.plot([x for x in c_losses_real], color='green', linewidth=1)\n",
    "plt.plot([x for x in c_losses_fake], color='red', linewidth=1)\n",
    "plt.plot([x for x in g_losses], color='orange', linewidth=1)\n",
    "\n",
    "plt.xlabel('epoch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.savefig(os.path.join(image_save_folder, 'train_loss_graph.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('gan_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d96dd6218930269b4cd8feca07fdf09d8d639cf486d090b424fe3934a00b48b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
