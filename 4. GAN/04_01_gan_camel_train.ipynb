{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "import torch.utils.data as data_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from GAN import Generator, Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 64\n",
    "D_lr = 8e-4\n",
    "G_lr = 4e-4\n",
    "data_path = '../data/full_numpy_bitmap_camel.npy'\n",
    "image_save_folder = './images/gan/'\n",
    "model_save_path = './gan_camel.pth'\n",
    "os.makedirs(image_save_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data url: https://console.cloud.google.com/storage/browser/quickdraw_dataset/full/numpy_bitmap?pli=1\n",
    "train_data = np.load(data_path)\n",
    "train_data = (train_data.astype('float32') - 127.5) / 127.5\n",
    "train_data = train_data.reshape(-1, 1, 28, 28)\n",
    "np.random.seed(np.random.randint(1, 10e6))\n",
    "np.random.shuffle(train_data)\n",
    "train_data = torch.from_numpy(train_data[:80000]).float()\n",
    "dataset = MyDataset(train_data)\n",
    "dataset_size = len(dataset)\n",
    "dataloader = DataLoader(dataset,\n",
    "                        shuffle=True,\n",
    "                        batch_size=batch_size,\n",
    "                        num_workers=4,\n",
    "                        pin_memory=True,\n",
    "                        drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.shape)\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(train_data[:25],\n",
    "                                         nrow=5,\n",
    "                                         padding=2,\n",
    "                                         normalize=True), (1, 2, 0)))\n",
    "plt.savefig(os.path.join(image_save_folder, 'original_images.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_model = Discriminator().to(device)\n",
    "G_model = Generator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_criterion = nn.BCELoss()\n",
    "G_criterion = nn.BCELoss()\n",
    "\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "D_optimizer = optim.RMSprop(params=D_model.parameters(), lr=D_lr)\n",
    "G_optimizer = optim.RMSprop(params=G_model.parameters(), lr=G_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_losses = []\n",
    "D_losses = []\n",
    "D_losses_real = []\n",
    "D_losses_fake = []\n",
    "D_accs = []\n",
    "D_accs_real = []\n",
    "D_accs_fake = []\n",
    "\n",
    "real_labels = torch.full((batch_size, ), real_label,\n",
    "                         dtype=torch.float, device=device, requires_grad=False)\n",
    "fake_labels = torch.full((batch_size, ), fake_label,\n",
    "                         dtype=torch.float, device=device, requires_grad=False)\n",
    "\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs in dataloader:\n",
    "        D_model.zero_grad()\n",
    "        \n",
    "        # Discriminator\n",
    "        # 진짜 데이터로 학습\n",
    "        inputs = inputs.to(device)\n",
    "        cur_batch_size = inputs.size(0)\n",
    "        output = D_model(inputs).view(-1)\n",
    "        D_acc_real = torch.mean(output)\n",
    "        D_loss_real = D_criterion(output, real_labels)\n",
    "        \n",
    "        # 가짜 데이터로 학습\n",
    "        noise = torch.randn(cur_batch_size, 100, device=device)\n",
    "        fake = G_model(noise)\n",
    "        \n",
    "        output = D_model(fake.detach()).view(-1)\n",
    "        D_acc_fake = 1 - torch.mean(output)\n",
    "        D_loss_fake = D_criterion(output, fake_labels)\n",
    "        \n",
    "        D_acc = (D_acc_real + D_acc_fake) * 0.5\n",
    "        D_loss = (D_loss_real + D_loss_fake) * 0.5\n",
    "        D_loss.backward()\n",
    "        D_optimizer.step()\n",
    "        \n",
    "        # Generator\n",
    "        # 업데이트한 discriminator 사용\n",
    "        # discriminator가 fake를 real이라고 판단하면 낮은 loss\n",
    "        # fake를 fake라고 판단하면 높은 loss\n",
    "        G_model.zero_grad()\n",
    "        output = D_model(fake).view(-1)\n",
    "        G_loss = G_criterion(output, real_labels)\n",
    "        G_loss.backward()\n",
    "        G_optimizer.step()\n",
    "        \n",
    "        print('iter: %d [D loss: (%.3f)(R %.3f, F %.3f)] [D acc: (%.3f)(%.3f, %.3f)] [G loss: %.3f]' %\n",
    "            (iter, D_loss.item(), D_loss_real.item(), D_loss_fake.item(), D_acc.item(), D_acc_real.item(), D_acc_fake.item(), G_loss.item()))\n",
    "        \n",
    "        G_losses.append(G_loss.item())\n",
    "        D_losses.append(D_loss.item())\n",
    "        D_losses_real.append(D_loss_real.item())\n",
    "        D_losses_fake.append(D_loss_fake.item())\n",
    "        D_accs.append(D_acc.item())\n",
    "        D_accs_real.append(D_acc_real.item())\n",
    "        D_accs_fake.append(D_acc_fake.item())\n",
    "    \n",
    "        # print('%d [D loss: (%.3f)(R %.3f, F %.3f)] [D acc: (%.3f)(%.3f, %.3f)] [G loss: %.3f]' %\n",
    "        #         (epoch, epoch_D_loss, epoch_D_loss_real, epoch_D_loss_fake, epoch_D_acc, epoch_D_acc_real, epoch_D_acc_fake, epoch_G_loss))\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(vutils.make_grid(fake[:25],\n",
    "                                                nrow=5,\n",
    "                                                padding=2,\n",
    "                                                normalize=True).detach().cpu(), (1, 2, 0)))\n",
    "    plt.savefig(os.path.join(image_save_folder, f'epoch_{epoch + 1}.png'))\n",
    "        \n",
    "torch.save({'Discriminator': D_model.state_dict(), 'Generator': G_model.state_dict(),}, model_save_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x for x in D_losses], color='black', linewidth=0.1)\n",
    "plt.plot([x for x in D_losses_real], color='green', linewidth=0.1)\n",
    "plt.plot([x for x in D_losses_fake], color='red', linewidth=0.1)\n",
    "plt.plot([x for x in G_losses], color='orange', linewidth=0.1)\n",
    "\n",
    "plt.xlabel('epoch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "\n",
    "plt.savefig(os.path.join(image_save_folder, 'loss_graph.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot([x for x in D_accs], color='black', linewidth=0.1)\n",
    "plt.plot([x for x in D_accs_real], color='green', linewidth=0.1)\n",
    "plt.plot([x for x in D_accs_fake], color='red', linewidth=0.1)\n",
    "\n",
    "plt.xlabel('batch', fontsize=18)\n",
    "plt.ylabel('accuracy', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "\n",
    "plt.savefig(os.path.join(image_save_folder, 'accuracy_graph.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_compare_images(img1, img2):\n",
    "    return np.mean(np.abs(img1 - img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "# loaded_models = torch.load(model_save_path, map_location=device)\n",
    "# D_model.load_state_dict(loaded_models['Discriminator'])\n",
    "# G_model.load_state_dict(loaded_models['Generator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_model.eval()\n",
    "G_model.eval()\n",
    "\n",
    "real_images = train_data[:25].numpy()\n",
    "fake_images = []\n",
    "\n",
    "for inputs in dataloader:\n",
    "    inputs = inputs.to(device)\n",
    "    b_size = inputs.size(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(b_size, 100, device=device)\n",
    "        fake = G_model(noise)\n",
    "        for fake_image in fake:\n",
    "            fake_images.append(fake_image.detach().cpu().numpy())\n",
    "    \n",
    "similar_images = np.zeros(real_images.shape)\n",
    "for i, real_image in enumerate(real_images):\n",
    "    min_val = l1_compare_images(real_image, fake_images[0])\n",
    "    similar_image = fake_images[0]\n",
    "    for fake_image in fake_images[1:]:\n",
    "        l1_dist = l1_compare_images(real_image, fake_image)\n",
    "        if l1_dist < min_val:\n",
    "            min_val = l1_dist\n",
    "            similar_image = fake_image\n",
    "            \n",
    "    similar_images[i] = similar_image\n",
    "    \n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(torch.from_numpy(similar_images),\n",
    "                                         nrow=5,\n",
    "                                         padding=2,\n",
    "                                         normalize=True), (1, 2, 0)))\n",
    "plt.savefig(os.path.join(image_save_folder, 'similar_images.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(train_data[:25],\n",
    "                                         nrow=5,\n",
    "                                         padding=2,\n",
    "                                         normalize=True), (1, 2, 0)))\n",
    "plt.savefig(os.path.join(image_save_folder, 'original_images.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 ('gan_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86945038929e12337cb19f89597171695d197df89cc82498a4710d2d3ad0cdf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
