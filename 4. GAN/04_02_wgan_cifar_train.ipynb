{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WGAN 훈련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from WGAN import Critic, Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 2000\n",
    "z_dim = 100\n",
    "D_lr = 5e-5\n",
    "G_lr = 5e-5\n",
    "n_critic = 5\n",
    "clip_threshold = 0.01\n",
    "data_path = '../data'\n",
    "image_save_folder = './images/wgan'\n",
    "\n",
    "os.makedirs(image_save_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "specific_label = 7\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=data_path, train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_indices = [idx for idx, target in enumerate(trainset.targets) if target is specific_label]\n",
    "trainset = trainset.data[train_indices]\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=data_path, train=False,\n",
    "                                       download=True, transform=transform)\n",
    "test_indices = [idx for idx, target in enumerate(testset.targets) if target is specific_label]\n",
    "testset = testset.data[test_indices]\n",
    "\n",
    "dataset = np.concatenate((trainset, testset), axis=0)\n",
    "dataset = np.transpose(dataset, (0, 3, 1, 2))\n",
    "dataset = (dataset - 127.5) / 127.5\n",
    "dataset = torch.from_numpy(dataset).float()\n",
    "\n",
    "dataset_size = len(dataset)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2, drop_last=True)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_batch_size = 25\n",
    "\n",
    "def imshow(image):\n",
    "    plt.figure(figsize=(18, 18))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(vutils.make_grid((image + 1) * 0.5,\n",
    "                                             nrow=5,\n",
    "                                             padding=2,\n",
    "                                             normalize=True), (1, 2, 0)))\n",
    "    plt.savefig(os.path.join(image_save_folder, 'sample_images.png'))\n",
    "    \n",
    "images = next(iter(dataloader))\n",
    "imshow(images[:sample_image_batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(z_dim).to(device)\n",
    "critic = Critic().to(device)\n",
    "generator.train()\n",
    "critic.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(critic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label = 1.\n",
    "fake_label = -1.\n",
    "\n",
    "D_optimizer = optim.RMSprop(params=critic.parameters(), lr=D_lr)\n",
    "G_optimizer = optim.RMSprop(params=generator.parameters(), lr=G_lr)\n",
    "# D_optimizer = optim.Adam(params=critic.parameters(), lr=D_lr, betas=[0.5, 0.999])\n",
    "# G_optimizer = optim.Adam(params=generator.parameters(), lr=G_lr, betas=[0.5, 0.999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_losses = []\n",
    "D_losses = []\n",
    "D_losses_real = []\n",
    "D_losses_fake = []\n",
    "\n",
    "one = torch.FloatTensor([1]).to(device)\n",
    "mone = one * -1\n",
    "\n",
    "num_G_input_batches = (len(dataloader) // n_critic) * batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_G_loss = 0.0\n",
    "    epoch_D_loss = 0.0\n",
    "    epoch_D_loss_real = 0.0\n",
    "    epoch_D_loss_fake = 0.0\n",
    "    num_inputs = 0\n",
    "    \n",
    "    for i, inputs in enumerate(dataloader):\n",
    "        critic.zero_grad()\n",
    "        \n",
    "        # 진짜 데이터로 학습\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        output = critic(inputs)\n",
    "        D_loss_real = -output.mean().view(-1)\n",
    "        \n",
    "        # 가짜 데이터로 학습\n",
    "        noise = torch.randn(batch_size, z_dim, device=device)\n",
    "        fake = generator(noise)\n",
    "        output = critic(fake)\n",
    "        D_loss_fake = output.mean().view(-1)\n",
    "        \n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "        D_loss.backward()\n",
    "        D_optimizer.step()\n",
    "        \n",
    "        epoch_D_loss += D_loss.item() * batch_size\n",
    "        epoch_D_loss_real += D_loss_real.item() * batch_size\n",
    "        epoch_D_loss_fake += D_loss_fake.item() * batch_size\n",
    "        \n",
    "        num_inputs += inputs.size(0)\n",
    "        \n",
    "        # 1-Lipshitz continuous function\n",
    "        for p in critic.parameters():\n",
    "            p.data.clamp_(-clip_threshold, clip_threshold)\n",
    "            \n",
    "        if (i + 1) % n_critic == 0:                    \n",
    "            for p in critic.parameters():\n",
    "                p.requires_grad = False\n",
    "            \n",
    "            # Generator\n",
    "            generator.zero_grad()\n",
    "            noise = torch.randn(batch_size, z_dim, device=device)\n",
    "            fake = generator(noise)\n",
    "            output = critic(fake)\n",
    "            G_loss = -output.mean().view(-1)\n",
    "            G_loss.backward()\n",
    "            G_optimizer.step()\n",
    "            \n",
    "            epoch_G_loss += G_loss.item() * batch_size\n",
    "            \n",
    "            for p in critic.parameters():\n",
    "                p.requires_grad = True\n",
    "        \n",
    "    epoch_D_loss /= num_inputs\n",
    "    epoch_D_loss_real /= num_inputs\n",
    "    epoch_D_loss_fake /= num_inputs\n",
    "    epoch_G_loss /= num_G_input_batches\n",
    "    \n",
    "    D_losses.append(epoch_D_loss)\n",
    "    D_losses_real.append(epoch_D_loss_real)\n",
    "    D_losses_fake.append(epoch_D_loss_fake)\n",
    "    G_losses.append(epoch_G_loss)\n",
    "    \n",
    "    print('%d [D loss: (%.3f)(R %.3f, F %.3f)] [G loss: %.3f]' %\n",
    "          (epoch + 1, epoch_D_loss, epoch_D_loss_real, epoch_D_loss_fake, epoch_G_loss))\n",
    "    \n",
    "    if epoch + 1 in [50, 100, 200, 500, 1000, 2000]:\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(np.transpose(vutils.make_grid((fake[:25] + 1) * 0.5,\n",
    "                                                 nrow=5,\n",
    "                                                 padding=2,\n",
    "                                                 normalize=False).detach().cpu(), (1, 2, 0)))\n",
    "        plt.savefig(os.path.join(image_save_folder, f'epoch_{epoch + 1}.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.plot([x for x in D_losses], color='black', linewidth=0.25)\n",
    "plt.plot([x for x in D_losses_real], color='green', linewidth=0.25)\n",
    "plt.plot([x for x in D_losses_fake], color='red', linewidth=0.25)\n",
    "plt.plot([x for x in G_losses], color='orange', linewidth=0.25)\n",
    "\n",
    "plt.xlabel('epoch', fontsize=18)\n",
    "plt.ylabel('loss', fontsize=16)\n",
    "\n",
    "plt.xlim(0, 2000)\n",
    "\n",
    "plt.savefig(os.path.join(image_save_folder, f'loss_graph.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_images(img1, img2):\n",
    "    return torch.mean(torch.abs(img1 - img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(25, z_dim, device=device)\n",
    "\n",
    "gen_imgs = generator(noise).detach().cpu()\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(gen_imgs / 2 + 0.5,\n",
    "                                         nrow=5,\n",
    "                                         padding=2,\n",
    "                                         normalize=False), (1, 2, 0)))\n",
    "plt.savefig(os.path.join(image_save_folder, f'gen_imgs.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_imgs = []\n",
    "\n",
    "for gen_img in gen_imgs:\n",
    "    min_val = 9999\n",
    "    min_img = dataset[0]\n",
    "    for real_imgs in dataloader:\n",
    "        for real_img in real_imgs:\n",
    "            real_img = real_img.numpy()\n",
    "            diff = compare_images(gen_img, real_img)\n",
    "            if min_val > diff:\n",
    "                min_val = diff\n",
    "                min_img = np.copy(real_img)\n",
    "        \n",
    "    closest_imgs.append(min_img)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(np.transpose(vutils.make_grid((torch.FloatTensor(closest_imgs) + 1) * 0.5,\n",
    "                                         nrow=5,\n",
    "                                         padding=2,\n",
    "                                         normalize=False), (1, 2, 0)))\n",
    "plt.savefig(os.path.join(image_save_folder, f'closest_real_imgs.png'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 ('gan_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86945038929e12337cb19f89597171695d197df89cc82498a4710d2d3ad0cdf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
